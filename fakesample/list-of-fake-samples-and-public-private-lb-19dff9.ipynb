{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "The statistics of training set and test set are very similar.\n",
    "\n",
    "However, one thing that caught my eye was the fact that the distribution of the number of unique values (across features) is significantly different between training set and test set.\n",
    "\n",
    "It seems that the test set consists of real samples as well as synthetic samples that were generated by sampling the real samples feature distributions (These are probably the \"rows which are not included in scoring\").\n",
    "\n",
    "If this is correct, then finding out which sample is synthetic, and which is real should be relatively easy task:\n",
    "\n",
    "Given a sample, we can go over its features and check if the feature value is unique.\n",
    "If at least one of the sample's features is unique, then the sample must be a real sample.\n",
    "It turns out that if a given sample has no unique values then it is a synthetic sample.\n",
    "(It doesn't have to be like that, but in this dataset the probability is seemingly to low that this would not be the case).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1c1fed0fe6b78f8b3c67a1cffe193269c8c270c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f0aa0167bf421693b44f10b99c88ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "test_path = '../input/test.csv'\n",
    "\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6f430d0d28f47be210c1905e88437e889d998a9"
   },
   "source": [
    "\n",
    "If the split between private and public LB sets was done before the resampling process of generating synthetic samples, then it's also possible to regenerate the two different sets.\n",
    "For each synthetic sample, we can go over its features and capture those features that have only one instance in the real samples set with the same value, this instance has to be one of the samples' generators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f61b7c454830f7f2d6790db98b4f080c4da30bf7"
   },
   "outputs": [],
   "source": [
    "df_test_real = df_test[real_samples_indexes].copy()\n",
    "df_test_unreal = df_test[synthetic_samples_indexes].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('real_samples_indexes_test.csv',real_samples_indexes,delimiter=',')\n",
    "np.savetxt('synthetic_samples_indexes_test.csv',synthetic_samples_indexes,delimiter=',')\n",
    "np.savetxt('df_test_real.csv',df_test_real,delimiter=',')\n",
    "np.savetxt('df_test_unreal.csv',df_test_unreal,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceb981914ce449295e30f059664c629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_path = '../input/train.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.drop(['target','ID_code'], axis=1, inplace=True)\n",
    "df_train = df_train.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_train)\n",
    "for feature in tqdm(range(df_train.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_train[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_real = df_train[real_samples_indexes].copy()\n",
    "df_train_unreal = df_train[synthetic_samples_indexes].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('real_samples_indexes_train.csv',real_samples_indexes,delimiter=',')\n",
    "np.savetxt('synthetic_samples_indexes_train.csv',synthetic_samples_indexes,delimiter=',')\n",
    "np.savetxt('df_train_real.csv',df_train_real,delimiter=',')\n",
    "np.savetxt('df_train_unreal.csv',df_train_unreal,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
